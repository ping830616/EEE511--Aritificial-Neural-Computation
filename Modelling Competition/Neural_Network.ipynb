{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet():\n",
    "    '''\n",
    "    A two layer neural network\n",
    "    '''\n",
    "        \n",
    "    def __init__(self, layers=[5,8,1], learning_rate=0.001, iterations=100):\n",
    "        self.params = {}\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "        self.loss = []\n",
    "        self.sample_size = None\n",
    "        self.layers = layers\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "                \n",
    "    def init_weights(self):\n",
    "        '''\n",
    "        Initialize the weights from a random normal distribution\n",
    "        '''\n",
    "        np.random.seed(1) # Seed the random number generator\n",
    "        self.params[\"W1\"] = np.random.randn(self.layers[0], self.layers[1]) \n",
    "        self.params['b1']  =np.random.randn(self.layers[1],)\n",
    "        self.params['W2'] = np.random.randn(self.layers[1],self.layers[2]) \n",
    "        self.params['b2'] = np.random.randn(self.layers[2],)\n",
    "    \n",
    "    def relu(self,Z):\n",
    "        '''\n",
    "        The ReLu activation function is to performs a threshold\n",
    "        operation to each input element where values less \n",
    "        than zero are set to zero.\n",
    "        '''\n",
    "        return np.maximum(0,Z)\n",
    "\n",
    "    def dRelu(self, x):\n",
    "        x[x<=0] = 0\n",
    "        x[x>0] = 1\n",
    "        return x\n",
    "\n",
    "    def eta(self, x):\n",
    "      ETA = 0.0000000001\n",
    "      return np.maximum(x, ETA)\n",
    "\n",
    "\n",
    "    def sigmoid(self,Z):\n",
    "        '''\n",
    "        The sigmoid function takes in real numbers in any range and \n",
    "        squashes it to a real-valued output between 0 and 1.\n",
    "        '''\n",
    "        return 1/(1+np.exp(-Z))\n",
    "\n",
    "    def entropy_loss(self,y, yhat):\n",
    "        nsample = len(y)\n",
    "        yhat_inv = 1.0 - yhat\n",
    "        y_inv = 1.0 - y\n",
    "        yhat = self.eta(yhat) ## clips value to avoid NaNs in log\n",
    "        yhat_inv = self.eta(yhat_inv) \n",
    "        loss = -1/nsample * (np.sum(np.multiply(np.log(yhat), y) + np.multiply((y_inv), np.log(yhat_inv))))\n",
    "        return loss\n",
    "\n",
    "    def forward_propagation(self):\n",
    "        '''\n",
    "        Performs the forward propagation\n",
    "        '''\n",
    "        \n",
    "        Z1 = self.X.dot(self.params['W1']) + self.params['b1']\n",
    "        A1 = self.relu(Z1)\n",
    "        Z2 = A1.dot(self.params['W2']) + self.params['b2']\n",
    "        yhat = self.sigmoid(Z2)\n",
    "        loss = self.entropy_loss(self.y,yhat)\n",
    "\n",
    "        # save calculated parameters     \n",
    "        self.params['Z1'] = Z1\n",
    "        self.params['Z2'] = Z2\n",
    "        self.params['A1'] = A1\n",
    "\n",
    "        return yhat,loss\n",
    "\n",
    "    def back_propagation(self,yhat):\n",
    "        '''\n",
    "        Computes the derivatives and update weights and bias according.\n",
    "        '''\n",
    "        y_inv = 1 - self.y\n",
    "        yhat_inv = 1 - yhat\n",
    "\n",
    "        dl_wrt_yhat = np.divide(y_inv, self.eta(yhat_inv)) - np.divide(self.y, self.eta(yhat))\n",
    "        dl_wrt_sig = yhat * (yhat_inv)\n",
    "        dl_wrt_z2 = dl_wrt_yhat * dl_wrt_sig\n",
    "\n",
    "        dl_wrt_A1 = dl_wrt_z2.dot(self.params['W2'].T)\n",
    "        dl_wrt_w2 = self.params['A1'].T.dot(dl_wrt_z2)\n",
    "        dl_wrt_b2 = np.sum(dl_wrt_z2, axis=0, keepdims=True)\n",
    "\n",
    "        dl_wrt_z1 = dl_wrt_A1 * self.dRelu(self.params['Z1'])\n",
    "        dl_wrt_w1 = self.X.T.dot(dl_wrt_z1)\n",
    "        dl_wrt_b1 = np.sum(dl_wrt_z1, axis=0, keepdims=True)\n",
    "\n",
    "        #update the weights and bias\n",
    "        self.params['W1'] = self.params['W1'] - self.learning_rate * dl_wrt_w1\n",
    "        self.params['W2'] = self.params['W2'] - self.learning_rate * dl_wrt_w2\n",
    "        self.params['b1'] = self.params['b1'] - self.learning_rate * dl_wrt_b1\n",
    "        self.params['b2'] = self.params['b2'] - self.learning_rate * dl_wrt_b2\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Trains the neural network using the specified data and labels\n",
    "        '''\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.init_weights() #initialize weights and bias\n",
    "\n",
    "\n",
    "        for i in range(self.iterations):\n",
    "            yhat, loss = self.forward_propagation()\n",
    "            self.back_propagation(yhat)\n",
    "            self.loss.append(loss)\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Predicts on a test data\n",
    "        '''\n",
    "        Z1 = X.dot(self.params['W1']) + self.params['b1']\n",
    "        A1 = self.relu(Z1)\n",
    "        Z2 = A1.dot(self.params['W2']) + self.params['b2']\n",
    "        pred = self.sigmoid(Z2)\n",
    "        return np.round(pred) \n",
    "\n",
    "    def acc(self, y, yhat):\n",
    "        '''\n",
    "        Calculates the accutacy between the predicted valuea and the truth labels\n",
    "        '''\n",
    "        acc = int(sum(y == yhat) / len(y) * 100)\n",
    "        return acc\n",
    "\n",
    "\n",
    "    def plot_loss(self):\n",
    "        '''\n",
    "        Plots the loss curve\n",
    "        '''\n",
    "        plt.plot(self.loss)\n",
    "        plt.xlabel(\"Iteration\")\n",
    "        plt.ylabel(\"logloss\")\n",
    "        plt.title(\"Loss curve for training\")\n",
    "        plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Energy Production</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1939-01-01</th>\n",
       "      <td>1</td>\n",
       "      <td>3.3842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939-02-01</th>\n",
       "      <td>2</td>\n",
       "      <td>3.4100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939-03-01</th>\n",
       "      <td>3</td>\n",
       "      <td>3.4875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939-04-01</th>\n",
       "      <td>4</td>\n",
       "      <td>3.5133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939-05-01</th>\n",
       "      <td>5</td>\n",
       "      <td>3.5133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>961</td>\n",
       "      <td>123.7687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-01</th>\n",
       "      <td>962</td>\n",
       "      <td>113.0736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-01</th>\n",
       "      <td>963</td>\n",
       "      <td>106.6538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01</th>\n",
       "      <td>964</td>\n",
       "      <td>88.6460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>965</td>\n",
       "      <td>92.3776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>965 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              #  Energy Production\n",
       "DATE                              \n",
       "1939-01-01    1             3.3842\n",
       "1939-02-01    2             3.4100\n",
       "1939-03-01    3             3.4875\n",
       "1939-04-01    4             3.5133\n",
       "1939-05-01    5             3.5133\n",
       "...         ...                ...\n",
       "2019-01-01  961           123.7687\n",
       "2019-02-01  962           113.0736\n",
       "2019-03-01  963           106.6538\n",
       "2019-04-01  964            88.6460\n",
       "2019-05-01  965            92.3776\n",
       "\n",
       "[965 rows x 2 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") #suppress warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "data = pd.read_csv('IPG2211A2N.csv',index_col=0)\n",
    "\n",
    "\n",
    "# second column: 'energy production'\n",
    "data.columns = ['Energy Production']\n",
    "\n",
    "# data['date'] = pd.date_range(start='1/1/1939', periods=len(data), freq='M')\n",
    "# data['DATE']=data['date'].apply(lambda x : x.replace(day=1))\n",
    "data.insert(0, '#', range(1, 1 + len(data)))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x values corresponding to dates\n",
    "\n",
    "\n",
    "#  The drop function removes the specified column from the dataset and returns the remaining features\n",
    "X = data.drop(columns=['#'])\n",
    "\n",
    "# -----------------------------------------\n",
    "# y values of energy production\n",
    "\n",
    "y = data['Energy Production'].values.reshape(x.shape[0], 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into train and test set\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(x, y, test_size=0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train set is (675, 1)\n",
      "Shape of test set is (290, 1)\n",
      "Shape of train label is (675, 1)\n",
      "Shape of test labels is (290, 1)\n"
     ]
    }
   ],
   "source": [
    "#standardize the dataset\n",
    "sc = StandardScaler()\n",
    "sc.fit(Xtrain)\n",
    "Xtrain = sc.transform(Xtrain)\n",
    "Xtest = sc.transform(Xtest)\n",
    "\n",
    "print(f\"Shape of train set is {Xtrain.shape}\")\n",
    "print(f\"Shape of test set is {Xtest.shape}\")\n",
    "print(f\"Shape of train label is {ytrain.shape}\")\n",
    "print(f\"Shape of test labels is {ytest.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (675,1) and (5,8) not aligned: 1 (dim 1) != 5 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-177-91e933c05a18>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNeuralNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# create the NN model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-138-d461bb709ac3>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[0myhat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_propagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mback_propagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-138-d461bb709ac3>\u001b[0m in \u001b[0;36mforward_propagation\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m         '''\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0mZ1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[0mA1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mZ2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mA1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (675,1) and (5,8) not aligned: 1 (dim 1) != 5 (dim 0)"
     ]
    }
   ],
   "source": [
    "nn = NeuralNet() # create the NN model\n",
    "nn.fit(Xtrain, ytrain) #train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
